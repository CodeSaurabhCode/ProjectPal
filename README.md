# ProjectPal - Full Stack AI Agent Development

A complete full-stack application featuring an AI-powered project management assistant built with Mastra framework and Astro frontend.

## ğŸ—ï¸ Architecture

- **Backend**: Node.js + TypeScript + Express + Mastra Framework
- **Frontend**: Astro + TypeScript
- **AI**: OpenAI GPT-4o-mini with function calling
- **Tools**: RAG for handbook queries, team directory, ticket creation
- **Architecture**: Modular with separated services, configuration, and data layers

## ğŸš€ Features

### Backend (Mastra-powered AI Agent)
- âœ… Express server with TypeScript
- âœ… `/api/chat` - Streaming chat endpoint with Server-Sent Events
- âœ… `/api/health` - Health check endpoint
- âœ… Mastra Agent orchestration
- âœ… RAG capabilities for PM_Handbook.txt with error handling
- âœ… SSE Service - Centralized Server-Sent Events handling
- âœ… Environment Configuration - Singleton pattern for config management
- âœ… Tool integration:
  - `getTeamDirectory` - Find available team members
  - `createProjectTicket` - Create project tickets
  - `queryHandbook` - Search PM handbook for policies
- âœ… Type-safe request validation with Zod
- âœ… Enhanced error logging and debugging
- âœ… CORS configuration for frontend

### Frontend (Astro)
- âœ… Modern chat interface with streaming support
- âœ… Centered welcome screen that transitions to chat layout
- âœ… Real-time Server-Sent Events handling
- âœ… Responsive design for mobile and desktop
- âœ… Connection status indicators
- âœ… Typing indicators and word-by-word message streaming
- âœ… Error handling and retry logic
- âœ… Clean UI without dev toolbar
- âœ… Markdown rendering with code syntax highlighting

## ğŸƒâ€â™‚ï¸ Getting Started

### Prerequisites
- Node.js 20.9.0 or higher
- OpenAI API key

### Backend Setup

1. **Navigate to backend directory:**
   ```bash
   cd backend
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Set up environment variables:**
   ```bash
   # Copy the example file
   cp .env.example .env
   
   # Edit .env and add your OpenAI API key
   OPENAI_API_KEY=your_openai_api_key_here
   ```

4. **Start the backend server:**
   ```bash
   # Development mode with auto-reload
   npm run server:dev
   
   # Or production mode
   npm run server
   ```

   The backend will be available at `http://localhost:3001`

### Frontend Setup

1. **Open a new terminal and navigate to frontend directory:**
   ```bash
   cd frontend
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Start the frontend development server:**
   ```bash
   npm run dev
   ```

   The frontend will be available at `http://localhost:4321`


## ğŸ“ Project Structure

```
ProjectPal/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ environment.ts           # Environment configuration
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â””â”€â”€ teamData.ts             # Team directory data
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ SSEService.ts           # Server-Sent Events service
â”‚   â”‚   â”œâ”€â”€ mastra/
â”‚   â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ project-assistant.ts # Main AI agent
â”‚   â”‚   â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ directory.ts        # Team directory tool
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ rag-tool.ts        # RAG handbook tool
â”‚   â”‚   â”‚   â””â”€â”€ index.ts               # Mastra configuration
â”‚   â”‚   â””â”€â”€ server.ts                  # Express server
â”‚   â”œâ”€â”€ docs/
â”‚   â”‚   â””â”€â”€ PM_handbook.txt            # Knowledge base
â”‚   â”œâ”€â”€ .env                           # Environment variables
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatHeader.astro
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatMessages.astro
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ChatInputArea.astro
â”‚   â”‚   â”‚   â””â”€â”€ Sidebar.astro
â”‚   â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”‚   â””â”€â”€ chat.ts                # Chat logic
â”‚   â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â”‚   â””â”€â”€ global.css
â”‚   â”‚   â”œâ”€â”€ layouts/
â”‚   â”‚   â”‚   â””â”€â”€ Layout.astro
â”‚   â”‚   â””â”€â”€ pages/
â”‚   â”‚       â””â”€â”€ index.astro            # Main chat interface
â”‚   â”œâ”€â”€ astro.config.mjs              # Astro configuration
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ”§ Key Features Implemented

### Backend Architecture
- **SSE Service**: Centralized Server-Sent Events handling with methods for different event types
- **Environment Config**: Singleton pattern for managing environment variables and app configuration
- **Data Segregation**: Separated business logic from static data (team directory)
- **Enhanced Error Handling**: Comprehensive logging and error tracking for RAG tool
- **Modular Structure**: Clean separation of concerns (config, data, services, agents, tools)

### Request/Response Format
```typescript
// Request
{
  "message": "Hi, I'm Saurabh, how are you"
}

// Streaming Response (Server-Sent Events)
data: {"type": "connected", "timestamp": "..."}
data: {"type": "status", "message": "Thinking..."}
data: {"type": "status", "message": "Using tool: query-handbook"}
data: {"type": "status", "message": "Generating response..."}
data: {"type": "chunk", "content": "Hello", "timestamp": "..."}
data: {"type": "chunk", "content": " Saurabh", "timestamp": "..."}
data: {"type": "complete", "response": "Full response", "toolCalls": [...]}
data: {"type": "end"}
```

### Streaming Configuration
- **Chunk Size**: 10 words per chunk
- **Chunk Delay**: 50ms between chunks
- **Tool Status Delay**: 300ms for status updates
- **Word-by-Word Streaming**: Smooth, natural response display

### Tool Functions
- **Team Directory**: Find available team members by role
- **Ticket Creation**: Create project tickets with assignments
- **Handbook RAG**: Query PM handbook for policies and procedures with enhanced error handling

### AI Agent Capabilities
- Natural language understanding
- Function calling with multiple tools
- Context-aware responses
- Project management expertise
- Real-time streaming responses

### Frontend Features
- **Welcome Screen**: Clean centered layout on initial load
- **Dynamic Layout**: Transitions from centered to chat layout when conversation starts
- **SSE Streaming**: Word-by-word display of AI responses
- **Status Indicators**: Shows AI thinking, tool usage, and response generation
- **Responsive Design**: Works on desktop and mobile
- **Clean Interface**: No dev toolbar or distracting elements

## ğŸ¯ Usage Examples

The AI assistant can handle various project management tasks:

1. **Team Management**: "Who are the available data scientists?"
2. **Policy Queries**: "What's the approval process for projects over $50k?"
3. **Ticket Creation**: "Create a kick-off ticket for the AI chatbot project"
4. **General Chat**: "Hi, how can you help me with my project?"

## ğŸš¦ Status

- âœ… Backend: Complete with modular architecture
- âœ… Frontend: Complete with centered welcome screen and streaming
- âœ… Integration: Full-stack working with SSE streaming
- âœ… AI Agent: Functional with tools and RAG
- âœ… Documentation: Complete setup guide and architecture docs
- âœ… Error Handling: Enhanced logging and debugging
- âœ… UI/UX: Clean, responsive, and user-friendly

## ğŸ“ Recent Improvements

### Backend
- Extracted SSE Service for centralized event streaming
- Implemented Environment Configuration singleton
- Segregated team data from business logic
- Enhanced RAG tool with comprehensive error handling and logging
- Fixed SSE streaming timing (status before AI generation, word-by-word after)

### Frontend
- Added centered welcome screen for initial state
- Dynamic layout transition from welcome to chat mode
- Removed Astro dev toolbar for cleaner UI
- Improved responsive design
- Enhanced streaming visualization with status indicators

## ğŸ”— API Endpoints

- `GET /api/health` - Health check
- `POST /api/chat` - Streaming chat with Server-Sent Events
- `POST /api/chat-simple` - Simple JSON response chat

## ğŸ› ï¸ Development

Both frontend and backend support hot-reloading during development:

```bash
# Backend with auto-reload
npm run server:dev

# Frontend with auto-reload  
npm run dev
```

The application is ready for development and testing!